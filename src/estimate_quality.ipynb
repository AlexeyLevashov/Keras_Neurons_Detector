{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alex-levashov/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import time\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import keras.backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from modules.images_viewer import ImagesViewer\n",
    "from modules.dataset import Dataset\n",
    "from modules.detector import FCNDetector\n",
    "from modules.images_viewer import ImagesViewer\n",
    "from modules.quality import compute_quality, compute_average_precision, find_optimal_threshold, get_precision_recall_curve\n",
    "import modules.models.loader as loader\n",
    "import modules.models.simple_model\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(image, size_w=8, size_h=8):\n",
    "    image = image[:, :, ::-1]\n",
    "    plt.figure(figsize=(size_w, size_h))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = FCNDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show image with rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data = dataset.images_data[0]\n",
    "if not config.load_all_images_to_ram:\n",
    "    image_data.load()\n",
    "image = image_data.image.copy()\n",
    "for true_rect in image_data.rects:\n",
    "    true_rect.draw(image, (0, 255, 0), 5)\n",
    "\n",
    "mask = cv2.resize(image_data.mask, (0, 0), fx=1.0/config.mask_downsample_rate, fy=1.0/config.mask_downsample_rate)\n",
    "nms_heat_map = detector.heat_map_nms(mask)\n",
    "rects = detector.obtain_rects(nms_heat_map, mask)\n",
    "reduced_rects = FCNDetector.rects_nms(rects)\n",
    "for rect in reduced_rects:\n",
    "    rect.draw(image, (255, 0, 0), 3)\n",
    "print(len(reduced_rects))\n",
    "show(image, 22, 22)\n",
    "if not config.load_all_images_to_ram:\n",
    "    image_data.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image_data in tqdm.tqdm_notebook(dataset.images_data):\n",
    "    if not config.load_all_images_to_ram:\n",
    "        image_data.load()\n",
    "    mask = cv2.resize(image_data.mask, (0, 0), fx=1.0/config.mask_downsample_rate, fy=1.0/config.mask_downsample_rate)\n",
    "    nms_heat_map = detector.heat_map_nms(mask)\n",
    "    rects = detector.obtain_rects(nms_heat_map, mask)\n",
    "    reduced_rects = FCNDetector.rects_nms(rects)\n",
    "    if len(image_data.rects) == len(reduced_rects):\n",
    "        print(\"{}:\\t ok\".format(image_data.image_name))\n",
    "    else:\n",
    "        print(\"{}:\\t missmatch {} != {}\".format(image_data.image_name, len(image_data.rects), len(reduced_rects)))\n",
    "        \n",
    "    if not config.load_all_images_to_ram:\n",
    "        image_data.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quality_objects_union = []\n",
    "for image_data in tqdm.tqdm_notebook(dataset.images_data):\n",
    "    if not config.load_all_images_to_ram:\n",
    "        image_data.load()\n",
    "    mask = cv2.resize(image_data.mask, (0, 0), fx=1.0/config.mask_downsample_rate, fy=1.0/config.mask_downsample_rate)\n",
    "    nms_heat_map = detector.heat_map_nms(mask)\n",
    "    rects = detector.obtain_rects(nms_heat_map, mask)\n",
    "    reduced_rects = FCNDetector.rects_nms(rects)\n",
    "    quality_objects = compute_quality(image_data.rects, reduced_rects)\n",
    "    quality_objects_union.extend(quality_objects)\n",
    "    ap_rate = compute_average_precision(quality_objects)\n",
    "    th, best_precision, best_recall, best_f1 = find_optimal_threshold(quality_objects)\n",
    "    \n",
    "    if ap_rate > 0.9999 and best_precision > 0.9999 and best_recall > 0.9999:\n",
    "        print(\"{}:\\t ok\".format(image_data.image_name))\n",
    "    else:\n",
    "        print(\"{}:\\t missmatch {}\".format(image_data.image_name, best_recall))\n",
    "        \n",
    "    if not config.load_all_images_to_ram:\n",
    "        image_data.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predictions = []\n",
    "for q in quality_objects:\n",
    "    true_labels.append(q.label)\n",
    "    predictions.append(q.prediction)\n",
    "precision, recall, thresholds = precision_recall_curve(true_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_optimal_threshold(quality_objects_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_batch (InputLayer)     (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "output_batch (Conv2D)        (None, None, None, 3)     1539      \n",
      "=================================================================\n",
      "Total params: 21,798,211\n",
      "Trainable params: 21,796,931\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "fcn_model_module = loader.get_fcn_model_module()\n",
    "fcn_model = fcn_model_module.FCNModel()\n",
    "detector = FCNDetector(fcn_model.model, osp.join(fcn_model.weights_dir, 'best_weights.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.jpg\n"
     ]
    }
   ],
   "source": [
    "image_data = dataset.images_data[59]\n",
    "print(image_data.image_name)\n",
    "image = image_data.image\n",
    "mask = detector.predict_heat_maps_batch(np.asarray([image]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1223803"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[:, :, 0].max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "show(mask, 26, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nms_heat_map = detector.heat_map_nms(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rects = detector.obtain_rects(nms_heat_map, mask)\n",
    "reduced_rects = FCNDetector.rects_nms(rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quality_objects = compute_quality(dataset.images_data[0].rects, reduced_rects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48734177215189872"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_rate = compute_average_precision(quality_objects)\n",
    "ap_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex-levashov/notebook/Keras_Neurons_Detector/src/modules/quality.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 2*(precision*recall)/(precision + recall)\n"
     ]
    }
   ],
   "source": [
    "threshold, precision, recall, f1_score = find_optimal_threshold(quality_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.70637668537139897,\n",
       " 0.78787878787878785,\n",
       " 0.33766233766233766,\n",
       " 0.47272727272727272)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = get_precision_recall_curve(quality_objects)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(precision)):\n",
    "    print(\"{} {}\".format(precision[i], recall[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "filtered_rects = [rect for rect in reduced_rects if rect.score > threshold]\n",
    "print(len(reduced_rects))\n",
    "print(len(filtered_rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_rects = image_data.image.copy()\n",
    "for true_rect in image_data.rects:\n",
    "    true_rect.draw(image_with_rects, (0, 255, 0), 5)\n",
    "for rect in reduced_rects:\n",
    "    rect.draw(image_with_rects, (255, 0, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_viewer = ImagesViewer()\n",
    "images_viewer.set_images([image, image_with_rects, mask*255, nms_heat_map*255])\n",
    "images_viewer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality over the all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quality_objects(image_data):\n",
    "    if not config.load_all_images_to_ram:\n",
    "        image_data.load()\n",
    "    mask = detector.predict_heat_maps_batch(np.asarray([image_data.image]))[0]\n",
    "    nms_heat_map = detector.heat_map_nms(mask)\n",
    "    rects = detector.obtain_rects(nms_heat_map, mask)\n",
    "    reduced_rects = FCNDetector.rects_nms(rects)\n",
    "    quality_objects = compute_quality(image_data.rects, reduced_rects)\n",
    "    ap_rate = compute_average_precision(quality_objects)\n",
    "    \n",
    "    print(\"{}:\\t {}\".format(image_data.image_name, ap_rate))\n",
    "\n",
    "    if not config.load_all_images_to_ram:\n",
    "        image_data.release()\n",
    "        \n",
    "    return quality_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_quality_objects = []\n",
    "for i in tqdm.tqdm_notebook(dataset.train_indices):\n",
    "    image_data = dataset.images_data[i]\n",
    "    train_quality_objects.extend(get_quality_objects(image_data))\n",
    "\n",
    "test_quality_objects = []\n",
    "for i in tqdm.tqdm_notebook(dataset.test_indices):\n",
    "    image_data = dataset.images_data[i]\n",
    "    test_quality_objects.extend(get_quality_objects(image_data))    \n",
    "\n",
    "train_ap_rate = compute_average_precision(train_quality_objects)\n",
    "print(\"Train AP: {}\".format(train_ap_rate))\n",
    "test_ap_rate = compute_average_precision(test_quality_objects)\n",
    "print(\"Test AP: {}\".format(test_ap_rate))\n",
    "\n",
    "threshold, best_precision, best_recall, best_f1 = find_optimal_threshold(train_quality_objects)\n",
    "print(\"Threshold {}, F1 score {}\".format(threshold, f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
